package benchmark

import (
	"context"
	"fmt"
	"math/rand"
	"os"
	"os/signal"
	"syscall"
	"time"

	"github.com/Layr-Labs/eigenda/common"
	"github.com/Layr-Labs/eigenda/litt"
	"github.com/Layr-Labs/eigenda/litt/benchmark/config"
	"github.com/Layr-Labs/eigenda/litt/littbuilder"
	"github.com/Layr-Labs/eigensdk-go/logging"
	"github.com/docker/go-units"
	"golang.org/x/time/rate"
)

// BenchmarkEngine is a tool for benchmarking LittDB performance.
type BenchmarkEngine struct {
	ctx    context.Context
	cancel context.CancelFunc
	logger logging.Logger

	// The configuration for the benchmark.
	config *config.BenchmarkConfig

	// The database to be benchmarked.
	db litt.DB

	// The table in the database where data is stored.
	table litt.Table

	// Keeps track of data to read and write.
	dataTracker *DataTracker

	// The maximum write throughput in bytes per second for each worker thread.
	writeBytesPerSecondPerThread uint64

	// The maximum read throughput in bytes per second for each worker thread.
	readBytesPerSecondPerThread uint64

	// The burst size for write rate limiting.
	writeBurstSize uint64

	// The burst size for read rate limiting.
	readBurstSize uint64

	// Records benchmark metrics.
	metrics *metrics
}

// NewBenchmarkEngine creates a new BenchmarkEngine with the given configuration.
func NewBenchmarkEngine(configPath string) (*BenchmarkEngine, error) {
	cfg, err := config.LoadConfig(configPath)
	if err != nil {
		return nil, fmt.Errorf("failed to load config file %s: %w", configPath, err)
	}

	cfg.LittConfig.Logger, err = common.NewLogger(cfg.LittConfig.LoggerConfig)
	if err != nil {
		return nil, fmt.Errorf("failed to create logger: %w", err)
	}

	cfg.LittConfig.ShardingFactor = uint32(len(cfg.LittConfig.Paths))

	db, err := littbuilder.NewDB(cfg.LittConfig)
	if err != nil {
		return nil, fmt.Errorf("failed to create db: %w", err)
	}

	table, err := db.GetTable("benchmark")
	if err != nil {
		return nil, fmt.Errorf("failed to create table: %w", err)
	}

	ttl := time.Duration(cfg.TTLHours * float64(time.Hour))
	err = table.SetTTL(ttl)
	if err != nil {
		return nil, fmt.Errorf("failed to set TTL for table: %w", err)
	}

	ctx, cancel := context.WithCancel(context.Background())

	dataTracker, err := NewDataTracker(ctx, cfg)
	if err != nil {
		cancel()
		return nil, fmt.Errorf("failed to create data tracker: %w", err)
	}

	writeBytesPerSecond := uint64(cfg.MaximumWriteThroughputMB * float64(units.MiB))
	writeBytesPerSecondPerThread := writeBytesPerSecond / uint64(cfg.WriterParallelism)

	// If we set the write burst size smaller than an individual value, then the rate limiter will never
	// permit any writes.
	writeBurstSize := uint64(cfg.ValueSizeMB * float64(units.MiB))

	readBytesPerSecond := uint64(cfg.MaximumReadThroughputMB * float64(units.MiB))
	readBytesPerSecondPerThread := readBytesPerSecond / uint64(cfg.ReaderParallelism)

	// If we set the read burst size smaller than an individual value we need to read, then the rate limiter will
	// never permit us to read that value.
	readBurstSize := dataTracker.LargestReadableValueSize()

	return &BenchmarkEngine{
		ctx:                          ctx,
		cancel:                       cancel,
		logger:                       cfg.LittConfig.Logger,
		config:                       cfg,
		db:                           db,
		table:                        table,
		dataTracker:                  dataTracker,
		writeBytesPerSecondPerThread: writeBytesPerSecondPerThread,
		readBytesPerSecondPerThread:  readBytesPerSecondPerThread,
		writeBurstSize:               writeBurstSize,
		readBurstSize:                readBurstSize,
		metrics:                      newMetrics(ctx, cfg.LittConfig.Logger, cfg),
	}, nil
}

// Logger returns the logger used by the benchmark engine.
func (b *BenchmarkEngine) Logger() logging.Logger {
	return b.logger
}

// Run executes the benchmark. This method blocks forever, or until the benchmark is stopped via control-C or
// encounters an error.
func (b *BenchmarkEngine) Run() error {

	// multiply 2 to make configured value the average
	sleepFactor := b.config.StartupSleepFactorSeconds * float64(time.Second) * 2.0

	for i := 0; i < b.config.WriterParallelism; i++ {
		// Sleep a short time to prevent all goroutines from starting in lockstep.
		time.Sleep(time.Duration(sleepFactor * rand.Float64()))

		go b.writer()
	}

	for i := 0; i < b.config.ReaderParallelism; i++ {
		// Sleep a short time to prevent all goroutines from starting in lockstep.
		time.Sleep(time.Duration(sleepFactor * rand.Float64()))

		go b.reader()
	}

	// Create a channel to listen for OS signals
	sigChan := make(chan os.Signal, 1)
	signal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)

	// Wait for signal
	<-sigChan

	// Cancel the context when signal is received
	b.cancel()

	return nil
}

// writer runs on a goroutine and writes data to the database.
func (b *BenchmarkEngine) writer() {
	maxBatchSize := uint64(b.config.BatchSizeMB * float64(units.MiB))
	throttle := rate.NewLimiter(rate.Limit(b.writeBytesPerSecondPerThread), int(b.writeBurstSize))

	for {
		select {
		case <-b.ctx.Done():
			break
		default:
			batchSize := uint64(0)

			for batchSize < maxBatchSize {
				writeInfo := b.dataTracker.GetWriteInfo()
				batchSize += uint64(len(writeInfo.Value))

				reservation := throttle.ReserveN(time.Now(), len(writeInfo.Value))
				if !reservation.OK() {
					panic(fmt.Sprintf("failed to reserve write quota for key %s", writeInfo.Key)) // TODO not clean
				}
				if reservation.Delay() > 0 {
					time.Sleep(reservation.Delay())
				}

				start := time.Now()

				err := b.table.Put(writeInfo.Key, writeInfo.Value)
				if err != nil {
					panic(fmt.Sprintf("failed to write data: %v", err)) // TODO not clean
				}

				b.metrics.reportWrite(time.Since(start), uint64(len(writeInfo.Value)))
				b.dataTracker.ReportWrite(writeInfo.KeyIndex)
			}

			start := time.Now()

			err := b.table.Flush()
			if err != nil {
				panic(fmt.Sprintf("failed to flush data: %v", err)) // TODO not clean
			}

			b.metrics.reportFlush(time.Since(start))
		}
	}
}

// verifyValue checks if the actual value read from the database matches the expected value.
func (b *BenchmarkEngine) verifyValue(expected *ReadInfo, actual []byte) error {
	if len(actual) != len(expected.Value) {
		return fmt.Errorf("read value size %d does not match expected size %d for key %s",
			len(actual), len(expected.Value), expected.Key)
	}
	for i := range actual {
		if actual[i] != expected.Value[i] {
			return fmt.Errorf("read value does not match expected value for key %s", expected.Key)
		}
	}
	return nil
}

// reader runs on a goroutine and reads data from the database.
func (b *BenchmarkEngine) reader() {
	throttle := rate.NewLimiter(rate.Limit(b.readBytesPerSecondPerThread), int(b.readBurstSize))

	for {
		select {
		case <-b.ctx.Done():
			break
		default:
			readInfo := b.dataTracker.GetReadInfo()

			reservation := throttle.ReserveN(time.Now(), len(readInfo.Value))
			if !reservation.OK() {
				panic(fmt.Sprintf("failed to reserve read quota for key %s", readInfo.Key)) // TODO not clean
			}
			if reservation.Delay() > 0 {
				time.Sleep(reservation.Delay())
			}

			start := time.Now()

			value, exists, err := b.table.Get(readInfo.Key)
			if err != nil {
				panic(fmt.Sprintf("failed to read data: %v", err)) // TODO not clean
			}

			b.metrics.reportRead(time.Since(start), uint64(len(readInfo.Value)))

			if !exists {
				panic(fmt.Sprintf("key %s not found in database", readInfo.Key)) // TODO not clean
			}
			err = b.verifyValue(readInfo, value)
			if err != nil {
				panic(fmt.Sprintf("value verification failed for key %s: %v", readInfo.Key, err)) // TODO not clean
			}
		}
	}
}
