package segment

import (
	"fmt"
	"math"
	"os"
	"path"
	"strconv"
	"strings"
	"time"

	"github.com/Layr-Labs/eigenda/litt/util"
	"github.com/Layr-Labs/eigensdk-go/logging"
)

// MetadataFileExtension is the file extension for the metadata file. Metadata file names have the form "X.metadata",
// where X is the segment index.
func getMetadataFileIndex(fileName string) (uint32, error) {
	indexString := path.Base(fileName)[:len(fileName)-len(MetadataFileExtension)]
	index, err := strconv.Atoi(indexString)
	if err != nil {
		return 0, fmt.Errorf("failed to parse index from file name %s: %v", fileName, err)
	}

	return uint32(index), nil
}

// getKeyFileIndex returns the index of the key file from the file name. Key file names have the form "X.keys",
// where X is the segment index.
func getKeyFileIndex(fileName string) (uint32, error) {
	baseName := path.Base(fileName)
	indexString := baseName[:len(baseName)-len(KeysFileExtension)]
	index, err := strconv.Atoi(indexString)
	if err != nil {
		return 0, fmt.Errorf("failed to parse index from file name %s: %v", fileName, err)
	}

	return uint32(index), nil
}

// getValueFileIndex returns the index of the value file from the file name. Value file names have the form
// "X-Y.values", where X is the segment index and Y is the shard number.
func getValueFileIndex(fileName string) (uint32, error) {
	baseName := path.Base(fileName)
	indexString := baseName[:len(baseName)-len(ValuesFileExtension)]

	parts := strings.Split(indexString, "-")
	if len(parts) != 2 {
		return 0, fmt.Errorf("invalid value file name %s", fileName)
	}
	indexString = parts[0]

	index, err := strconv.Atoi(indexString)
	if err != nil {
		return 0, fmt.Errorf("failed to parse index from file name %s: %v", fileName, err)
	}

	return uint32(index), nil
}

// getValueFileShard returns the shard number of the value file from the file name. Value file names have the form
// "X-Y.values", where X is the segment index and Y is the shard number.
func getValueFileShard(fileName string) (uint32, error) {
	baseName := path.Base(fileName)
	indexString := baseName[:len(baseName)-len(ValuesFileExtension)]

	parts := strings.Split(indexString, "-")
	if len(parts) != 2 {
		return 0, fmt.Errorf("invalid value file name %s", fileName)
	}
	shardString := parts[1]

	shard, err := strconv.Atoi(shardString)
	if err != nil {
		return 0, fmt.Errorf("failed to parse shard from file name %s: %v", fileName, err)
	}

	return uint32(shard), nil
}

// scanDirectories scans directories for segment files and returns a map of metadata, key, and value files.
// Also returns a list of garbage files that should be deleted. Does not do anything to files with unrecognized
// extensions.
func scanDirectories(logger logging.Logger, rootDirectories []string) (
	metadataFiles map[uint32]string,
	keyFiles map[uint32]string,
	valueFiles map[uint32][]string,
	garbageFiles []string,
	highestSegmentIndex uint32,
	lowestSegmentIndex uint32,
	isEmpty bool,
	err error) {

	highestSegmentIndex = uint32(0)
	lowestSegmentIndex = uint32(math.MaxUint32)

	// key is the file's segment index, value is the file's path
	metadataFiles = make(map[uint32]string)
	keyFiles = make(map[uint32]string)
	valueFiles = make(map[uint32][]string)

	garbageFiles = make([]string, 0)

	for _, rootDirectory := range rootDirectories {
		files, err := os.ReadDir(rootDirectory)
		if err != nil {
			return nil, nil, nil, nil,
				0, 0, false,
				fmt.Errorf("failed to read directory %s: %v", rootDirectory, err)
		}

		for _, file := range files {
			if file.IsDir() {
				continue
			}

			fileName := file.Name()
			extension := path.Ext(fileName)
			filePath := path.Join(rootDirectory, fileName)
			var index uint32

			switch extension {
			case MetadataSwapExtension:
				garbageFiles = append(garbageFiles, filePath)
				continue
			case MetadataFileExtension:
				index, err = getMetadataFileIndex(fileName)
				if err != nil {
					return nil, nil, nil, nil,
						0, 0, false,
						fmt.Errorf("failed to get file index: %v", err)
				}
				metadataFiles[index] = filePath
			case KeysFileExtension:
				index, err = getKeyFileIndex(fileName)
				if err != nil {
					return nil, nil, nil, nil,
						0, 0, false,
						fmt.Errorf("failed to get file index: %v", err)
				}
				keyFiles[index] = filePath
			case ValuesFileExtension:
				index, err = getValueFileIndex(fileName)
				if err != nil {
					return nil, nil, nil, nil,
						0, 0, false,
						fmt.Errorf("failed to get file index: %v", err)
				}
				valueFiles[index] = append(valueFiles[index], filePath)
			default:
				logger.Debugf("Ignoring unknown file %s", filePath)
				continue
			}

			if index > highestSegmentIndex {
				highestSegmentIndex = index
			}
			if index < lowestSegmentIndex {
				lowestSegmentIndex = index
			}
		}
	}

	if lowestSegmentIndex == math.MaxUint32 {
		// No segments found, fix the index.
		lowestSegmentIndex = 0
	}

	isEmpty = len(metadataFiles) == 0 && len(keyFiles) == 0 && len(valueFiles) == 0

	return metadataFiles, keyFiles, valueFiles, garbageFiles, highestSegmentIndex, lowestSegmentIndex, isEmpty, nil
}

// diagnoseMissingFile decides what to do with specific missing files. If the segment is either the segment
// with the lowest index or the segment with the highest index, it is possible for files to be missing due to
// non-catastrophic reasons (i.e. a crash during cleanup). If the segment is neither the lowest nor highest segment,
// then missing files signal non-recoverable DB corruption, and an error is returned.
func diagnoseMissingFile(
	logger logging.Logger,
	index uint32,
	lowestFileIndex uint32,
	highestFileIndex uint32,
	fileType string,
	damagedSegments map[uint32]struct{}) error {

	if index == highestFileIndex {
		// This can happen if we crash while creating a new segment. Recoverable.
		logger.Warnf("Missing %s file for last segment %d", fileType, index)
		damagedSegments[index] = struct{}{}
	} else if index == lowestFileIndex {
		// This can happen when deleting the oldest segment. Recoverable.
		logger.Warnf("Missing %s file for first segment %d", fileType, index)
		damagedSegments[index] = struct{}{}
	} else {
		// Database is missing internal files. Catastrophic failure.
		return fmt.Errorf("missing %s file for segment %d", fileType, index)
	}

	return nil
}

// lookForMissingFiles ensures that all files that should be present are actually present. Returns an error
// if files are missing in a way that cannot be recovered. If recoverable, returns a set of segments that
// have orphaned files.
func lookForMissingFiles(
	logger logging.Logger,
	lowestSegmentIndex uint32,
	highestSegmentIndex uint32,
	metadataFiles map[uint32]string,
	keyFiles map[uint32]string,
	valueFiles map[uint32][]string,
) (orphanedFiles []string, damagedSegments map[uint32]struct{}, error error) {

	orphanedFiles = make([]string, 0)
	damagedSegments = make(map[uint32]struct{})

	for segment := lowestSegmentIndex; segment <= highestSegmentIndex; segment++ {

		potentialOrphans := make([]string, 0)
		segmentMissingFiles := false

		// Check for missing metadata file.
		_, metadataPresent := metadataFiles[segment]
		if metadataPresent {
			potentialOrphans = append(potentialOrphans, metadataFiles[segment])
		} else {
			segmentMissingFiles = true
			err := diagnoseMissingFile(
				logger,
				segment,
				lowestSegmentIndex,
				highestSegmentIndex,
				"metadata",
				damagedSegments)
			if err != nil {
				return nil, nil, err
			}
		}

		// Check for missing key file.
		_, keysPresent := keyFiles[segment]
		if keysPresent {
			potentialOrphans = append(potentialOrphans, keyFiles[segment])
		} else {
			segmentMissingFiles = true
			err := diagnoseMissingFile(
				logger,
				segment,
				lowestSegmentIndex,
				highestSegmentIndex,
				"key",
				damagedSegments)
			if err != nil {
				return nil, nil, err
			}
		}

		// Check for missing value files (there should be exactly one value file per shard).
		if !metadataPresent {
			// If the metadata file is missing but we haven't yet returned an error, all of the value files
			// are automatically considered orphaned.
			orphanedFiles = append(orphanedFiles, valueFiles[segment]...)
		} else {

			// We need to know the sharding factor to check for missing value files.
			metadataPath := metadataFiles[segment]
			metadataDirectory := path.Dir(metadataPath)

			metadata, err := newMetadataFile(segment, 0, 0, metadataDirectory)
			if err != nil {
				return nil, nil,
					fmt.Errorf("failed to load metadata file: %v", err)
			}

			if uint32(len(valueFiles[segment])) > metadata.shardingFactor {
				return nil, nil,
					fmt.Errorf("too many value files for segment %d, expected %d, got %d",
						segment, metadata.shardingFactor, len(valueFiles[segment]))
			}

			// Catalogue the shards we do have.
			shardsPresent := make(map[uint32]struct{})
			for _, vFile := range valueFiles[segment] {
				shard, err := getValueFileShard(vFile)
				if err != nil {
					return nil, nil,
						fmt.Errorf("failed to get shard from value file: %v", err)
				}
				shardsPresent[shard] = struct{}{}
				potentialOrphans = append(potentialOrphans, vFile)
			}

			// Check that we have each shard.
			for shard := uint32(0); shard < metadata.shardingFactor; shard++ {
				_, shardPresent := shardsPresent[shard]
				if !shardPresent {
					segmentMissingFiles = true
					err = diagnoseMissingFile(
						logger,
						segment,
						lowestSegmentIndex,
						highestSegmentIndex,
						fmt.Sprintf("shard-%d", shard),
						damagedSegments)
					if err != nil {
						return nil, nil, err
					}
				}
			}
		}

		if segmentMissingFiles {
			// If we are missing a file in this segment, all other files in the segment are considered orphaned.
			orphanedFiles = append(orphanedFiles, potentialOrphans...)
		}
	}

	return orphanedFiles, damagedSegments, nil
}

// deleteOrphanedFiles deletes any files that are in the orphan set.
func deleteOrphanedFiles(logger logging.Logger, orphanedFiles []string) error {
	for _, orphanedFile := range orphanedFiles {
		logger.Infof("deleting orphaned file %s", orphanedFile)
		err := os.Remove(orphanedFile)
		if err != nil {
			return fmt.Errorf("failed to remove orphaned file %s: %v", orphanedFile, err)
		}
	}
	return nil
}

// linkSegments links together adjacent segments via SetNextSegment().
func linkSegments(lowestSegmentIndex uint32, highestSegmentIndex uint32, segments map[uint32]*Segment) error {
	if lowestSegmentIndex == highestSegmentIndex {
		// Only one segment, nothing to link. This is checked explicitly to avoid 0-1 underflow.
		return nil
	}

	for i := lowestSegmentIndex; i <= highestSegmentIndex-1; i++ {
		first, ok := segments[i]
		if !ok {
			return fmt.Errorf("missing segment %d", i)
		}
		second, ok := segments[i+1]
		if !ok {
			return fmt.Errorf("missing segment %d", i+1)
		}
		first.SetNextSegment(second)
	}
	return nil
}

// GatherSegmentFiles scans a directory for segment files and loads them into memory. It also deletes
// orphaned files and checks for corrupted files. It creates a new mutable segment at the end.
func GatherSegmentFiles(
	logger logging.Logger,
	fatalErrorHandler *util.FatalErrorHandler,
	rootDirectories []string,
	now time.Time,
	shardingFactor uint32,
	salt uint32,
	fsync bool) (lowestSegmentIndex uint32, highestSegmentIndex uint32, segments map[uint32]*Segment, err error) {

	// Scan the root directories for segment files.
	metadataFiles, keyFiles, valueFiles, garbageFiles, highestSegmentIndex, lowestSegmentIndex, isEmpty, err :=
		scanDirectories(logger, rootDirectories)
	if err != nil {
		return 0, 0, nil,
			fmt.Errorf("failed to scan directory: %v", err)
	}

	segments = make(map[uint32]*Segment)

	// Delete any garbage files. Ignore files with unrecognized extensions.
	if !isEmpty {
		for _, garbageFile := range garbageFiles {
			logger.Infof("deleting file %s", garbageFile)
			err = os.Remove(garbageFile)
			if err != nil {
				return 0, 0, nil,
					fmt.Errorf("failed to remove garbage file %s: %v", garbageFile, err)
			}
		}

		// Check for missing files.
		orphanedFiles, damagedSegments, err := lookForMissingFiles(
			logger,
			lowestSegmentIndex,
			highestSegmentIndex,
			metadataFiles,
			keyFiles,
			valueFiles)
		if err != nil {
			return 0, 0, nil,
				fmt.Errorf("there are one or more missing files: %v", err)
		}

		// Clean up any orphaned segment files.
		err = deleteOrphanedFiles(logger, orphanedFiles)
		if err != nil {
			return 0, 0, nil,
				fmt.Errorf("failed to delete orphaned files: %v", err)
		}

		// Adjust the segment range to exclude orphaned segments.
		if _, ok := damagedSegments[highestSegmentIndex]; ok {
			highestSegmentIndex--
		}
		if _, ok := damagedSegments[lowestSegmentIndex]; ok {
			lowestSegmentIndex++
		}

		// Load all healthy segments.
		for i := lowestSegmentIndex; i <= highestSegmentIndex; i++ {
			segment, err := NewSegment(
				logger, fatalErrorHandler, i, rootDirectories, now, shardingFactor, salt, true, fsync)
			if err != nil {
				return 0, 0, nil,
					fmt.Errorf("failed to create segment %d: %v", i, err)
			}
			segments[i] = segment
		}
	}

	// Stitch together the segments.
	err = linkSegments(lowestSegmentIndex, highestSegmentIndex, segments)
	if err != nil {
		return 0, 0, nil,
			fmt.Errorf("failed to link segments: %v", err)
	}

	return lowestSegmentIndex, highestSegmentIndex, segments, nil
}
